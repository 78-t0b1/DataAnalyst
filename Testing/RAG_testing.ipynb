{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pyprojroot import here\n",
    "import pandas as pd\n",
    "import chromadb\n",
    "from openai import AzureOpenAI\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "print(load_dotenv())\n",
    "\n",
    "import os\n",
    "\n",
    "# ROOT_DIR = os.path.dirname(os.path.abspath(__file__))\n",
    "\n",
    "# SUST_DB_PATH = os.path.join(ROOT_DIR, 'Data/DB/Sustain.db')\n",
    "# CHRIS_DB_PATH = os.path.join(ROOT_DIR, 'Data/DB/Chrismas.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import SQLDatabase\n",
    "\n",
    "sust_db = SQLDatabase.from_uri(F\"sqlite:///../Data/DB/Sustain.db\")\n",
    "chris_db = SQLDatabase.from_uri(F\"sqlite:///../Data/DB/Chrismas.db\")\n",
    "# print(sust_db.dialect)\n",
    "# print(sust_db.get_usable_table_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Query to get the entire schema\n",
    "sust_res = sust_db.run(\"SELECT sql FROM sqlite_master WHERE type='table';\")\n",
    "chris_res = chris_db.run(\"SELECT sql FROM sqlite_master WHERE type='table';\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class SubmitFinalAnswer(BaseModel):\n",
    "    \"\"\"Submit the final answer to the user based on the query results.\"\"\"\n",
    "\n",
    "    final_answer: str = Field(..., description=\"The final answer to the user\")\n",
    "\n",
    "\n",
    "Master_Agent = f\"\"\"\n",
    "    You are a Business Analyst who recieved this question from client. You have two SQL agents one is for Chrismas.db with schema : {chris_res} , and second for Sustain.db with schema : {sust_res}. You have to decide which database above question belongs to. If it belongs to both DB redifine question in two questions where one question is explicit for one and second for another.\n",
    "    Please give output in following format always:\n",
    "    \n",
    "    Orignal Question:\n",
    "\n",
    "    Sustain.db Question: \n",
    "\n",
    "    Chrismas.db Question:\n",
    "\n",
    "    Response:\n",
    "\n",
    "    If question belongs to only one db keep other option empty.\n",
    "    \n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "query_gen_prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", Master_Agent), (\"placeholder\", \"{messages}\")]\n",
    ")\n",
    "query_gen = query_gen_prompt | ChatOpenAI(model=\"gpt-4o\", temperature=0).bind_tools(\n",
    "    [SubmitFinalAnswer]\n",
    ")\n",
    "\n",
    "res = query_gen.invoke({\"messages\": [\"what is this application about?\"]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='This application is designed to help determine which database a given question belongs to, based on the schema of two databases: Chrismas.db and Sustain.db. If a question belongs to both databases, the application will redefine the question into two separate questions, each specific to one database. The output format includes the original question, the question for Sustain.db, the question for Chrismas.db, and the response.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 83, 'prompt_tokens': 2692, 'total_tokens': 2775, 'prompt_tokens_details': {'cached_tokens': 2560}, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_6b68a8204b', 'finish_reason': 'stop', 'logprobs': None}, id='run-a0c6eaea-a2b3-4f5c-8834-1f33b3d2c8f5-0', usage_metadata={'input_tokens': 2692, 'output_tokens': 83, 'total_tokens': 2775})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = res.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res['content'].split('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'tanmay jagtap' in 'mycfhsdkvnfd cfdc  cfdc tanmay jagtap'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Orignal Question': 'fdvdsv', 'Sustain.db Question': 'vdsvsdv', 'Chrismas.db Question': '', 'Response': 'vsdvsdv'}\n"
     ]
    }
   ],
   "source": [
    "res = \"\"\"\n",
    "Orignal Question: fdvdsv\n",
    "\n",
    "Sustain.db Question: vdsvsdv\n",
    "\n",
    "Chrismas.db Question:\n",
    "\n",
    "Response: vsdvsdv\n",
    "\"\"\"\n",
    "\n",
    "# Split the response by new lines\n",
    "responces = res.split('\\n')\n",
    "\n",
    "# Initialize the dictionary\n",
    "main_res = {'Orignal Question': '', 'Sustain.db Question': '', 'Chrismas.db Question': '', 'Response': ''}\n",
    "\n",
    "for responce in responces:\n",
    "    responce = responce.strip()  # Remove leading/trailing spaces\n",
    "    if responce:  # Skip empty lines\n",
    "        # Loop through the dictionary keys and find the ones that match\n",
    "        for key in main_res.keys():\n",
    "            if responce.startswith(key):\n",
    "                res_sep = responce.split(':', 1)  # Split only at the first colon\n",
    "                main_res[res_sep[0]] = res_sep[1].strip()  # Assign the value and strip extra spaces\n",
    "\n",
    "print(main_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
